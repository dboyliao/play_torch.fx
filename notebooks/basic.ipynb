{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3de25e8-097b-405d-af51-ce29194dbf4a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-11-04T02:43:28.576083Z",
     "iopub.status.busy": "2024-11-04T02:43:28.575510Z",
     "iopub.status.idle": "2024-11-04T02:43:34.877107Z",
     "shell.execute_reply": "2024-11-04T02:43:34.875463Z",
     "shell.execute_reply.started": "2024-11-04T02:43:28.576020Z"
    },
    "frozen": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dboy/open_source/play_torch.fx/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "from transformers import ViTImageProcessor, ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95115a7d-d819-4a38-83ee-d63edf920c42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9c04c2-002c-467a-84f1-4b362010aeca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbolically traced variables cannot be used as inputs to control flow\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gm = fx.symbolic_trace(model)\n",
    "except fx.proxy.TraceError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01782a63-ca91-4875-9b36-129f8c8e970e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b7164f-7324-4333-836d-a3bff4b2038d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "class GraphCollector:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._subgraphs = []\n",
    "\n",
    "    def reset(self):\n",
    "        self._subgraphs.clear()\n",
    "\n",
    "    def __call__(self, gm: fx.GraphModule, sameple_inputs):\n",
    "        self._subgraphs.append(deepcopy(gm.graph))\n",
    "        return gm.forward\n",
    "        \n",
    "    @property\n",
    "    def subgraphs(self):\n",
    "        return self._subgraphs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6dfe28-1969-4011-b41a-bc6708fd505e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "collector = GraphCollector()\n",
    "model_ = torch.compile(model, backend=collector).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece44fd7-bf5d-4cb0-bfb3-8d99ae9846f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "collector.reset()\n",
    "_ = model_(**{k: v.to(\"cuda:0\") for k, v in inputs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f2a51e4-9aad-4563-ac09-808a185d2048",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "graph = collector.subgraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd504041-74eb-4df1-b0c8-6fc09ae7b6ea",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.fx.graph.Graph at 0x79d2b0d34880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1b1ac39-c0da-432c-9f36-32bf2e2f3cda",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "nodes = [n for n in graph.nodes] # nodes in topological ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09de93d3-ef23-4ca5-9647-6ac5083789fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "node = nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed449c77-2e54-46e6-a4eb-e57e5bcd820a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('placeholder', [], {conv2d: None})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.op, node.all_input_nodes, node.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4969c8e1-1d38-420b-bffe-b9a33786ec8a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l_pixel_values_'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "411ac3fe-8a20-4d98-bde8-6f26e03a1244",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L_pixel_values_'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "212c71a9-c6ee-4bb4-bd31-4b096286d627",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.fx.node'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(node).__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d73b095f-8126-4e59-a83c-00eea1fdd5e0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stack_trace': '  File \"/home/dboy/open_source/play_torch.fx/.venv/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py\", line 620, in forward\\n    if pixel_values is None:\\n',\n",
       " 'example_value': FakeTensor(..., device='cuda:0', size=(1, 3, 224, 224)),\n",
       " 'tensor_dict': {},\n",
       " 'grapharg': GraphArg(source=LocalSource(local_name='pixel_values', cell_or_freevar=False), _example=<torch.utils.weak.TensorWeakRef object at 0x7969d4079b90>, pass_arg_as_tensor=False, fake_tensor=FakeTensor(..., device='cuda:0', size=(1, 3, 224, 224)), is_tensor=True, example_strong_ref=None)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cacd5c8-ebca-4b30-9b04-26fb10613775",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Argument'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Argument'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtype_expr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a ``Node`` and add it to the ``Graph`` at the current insert-point.\n",
       "Note that the current insert-point can be set via :meth:`Graph.inserting_before`\n",
       "and :meth:`Graph.inserting_after`.\n",
       "\n",
       "Args:\n",
       "    op (str): the opcode for this Node. One of 'call_function', 'call_method', 'get_attr',\n",
       "        'call_module', 'placeholder', or 'output'. The semantics of these opcodes are\n",
       "        described in the ``Graph`` docstring.\n",
       "\n",
       "    args (Optional[Tuple[Argument, ...]]): is a tuple of arguments to this node.\n",
       "\n",
       "    kwargs (Optional[Dict[str, Argument]]): the kwargs of this Node\n",
       "\n",
       "    name (Optional[str]): an optional string name for the ``Node``.\n",
       "        This will influence the name of the value assigned to in the\n",
       "        Python generated code.\n",
       "\n",
       "    type_expr (Optional[Any]): an optional type annotation representing the\n",
       "        Python type the output of this node will have.\n",
       "\n",
       "Returns:\n",
       "\n",
       "    The newly-created and inserted node.\n",
       "\n",
       ".. note::\n",
       "    Backwards-compatibility for this API is guaranteed.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/open_source/play_torch.fx/.venv/lib/python3.11/site-packages/torch/fx/graph.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.create_node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef7583c6-4047-4d99-a71d-3ac905b6e5ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L_pixel_values_'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63adf314-7b10-4a4e-b231-f637183e1e6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "node = graph.create_node(\"placeholder\", target=\"my_ph_value\", name=\"my_ph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5af4bc93-e0bd-4561-b1cb-41aef8239fed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.is_impure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b01f913c-7c73-4e31-909c-dada52aee7f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('L_pixel_values_', 'l_pixel_values_'),\n",
       " ('L_self_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_',\n",
       "  'l_self_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_'),\n",
       " ('L_self_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_',\n",
       "  'l_self_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_'),\n",
       " ('L_self_modules_embeddings_parameters_cls_token_',\n",
       "  'l_self_modules_embeddings_parameters_cls_token_'),\n",
       " ('L_self_modules_embeddings_parameters_position_embeddings_',\n",
       "  'l_self_modules_embeddings_parameters_position_embeddings_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_weight_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_'),\n",
       " ('L_self_modules_layernorm_parameters_bias_',\n",
       "  'l_self_modules_layernorm_parameters_bias_'),\n",
       " ('L_self_modules_layernorm_parameters_weight_',\n",
       "  'l_self_modules_layernorm_parameters_weight_'),\n",
       " ('L_self_modules_pooler_modules_dense_parameters_bias_',\n",
       "  'l_self_modules_pooler_modules_dense_parameters_bias_'),\n",
       " ('L_self_modules_pooler_modules_dense_parameters_weight_',\n",
       "  'l_self_modules_pooler_modules_dense_parameters_weight_'),\n",
       " ('contiguous', 'context_layer_1'),\n",
       " ('contiguous', 'context_layer_10'),\n",
       " ('contiguous', 'context_layer_13'),\n",
       " ('contiguous', 'context_layer_16'),\n",
       " ('contiguous', 'context_layer_19'),\n",
       " ('contiguous', 'context_layer_22'),\n",
       " ('contiguous', 'context_layer_25'),\n",
       " ('contiguous', 'context_layer_28'),\n",
       " ('contiguous', 'context_layer_31'),\n",
       " ('contiguous', 'context_layer_34'),\n",
       " ('contiguous', 'context_layer_4'),\n",
       " ('contiguous', 'context_layer_7'),\n",
       " ('expand', 'cls_tokens'),\n",
       " ('flatten', 'flatten'),\n",
       " ('my_ph_value', 'my_ph_1'),\n",
       " ('my_ph_value', 'my_ph_2'),\n",
       " ('output', 'output'),\n",
       " ('permute', 'key_layer'),\n",
       " ('permute', 'key_layer_1'),\n",
       " ('permute', 'key_layer_10'),\n",
       " ('permute', 'key_layer_11'),\n",
       " ('permute', 'key_layer_2'),\n",
       " ('permute', 'key_layer_3'),\n",
       " ('permute', 'key_layer_4'),\n",
       " ('permute', 'key_layer_5'),\n",
       " ('permute', 'key_layer_6'),\n",
       " ('permute', 'key_layer_7'),\n",
       " ('permute', 'key_layer_8'),\n",
       " ('permute', 'key_layer_9'),\n",
       " ('permute', 'permute_11'),\n",
       " ('permute', 'permute_15'),\n",
       " ('permute', 'permute_19'),\n",
       " ('permute', 'permute_23'),\n",
       " ('permute', 'permute_27'),\n",
       " ('permute', 'permute_3'),\n",
       " ('permute', 'permute_31'),\n",
       " ('permute', 'permute_35'),\n",
       " ('permute', 'permute_39'),\n",
       " ('permute', 'permute_43'),\n",
       " ('permute', 'permute_47'),\n",
       " ('permute', 'permute_7'),\n",
       " ('permute', 'query_layer'),\n",
       " ('permute', 'query_layer_1'),\n",
       " ('permute', 'query_layer_10'),\n",
       " ('permute', 'query_layer_11'),\n",
       " ('permute', 'query_layer_2'),\n",
       " ('permute', 'query_layer_3'),\n",
       " ('permute', 'query_layer_4'),\n",
       " ('permute', 'query_layer_5'),\n",
       " ('permute', 'query_layer_6'),\n",
       " ('permute', 'query_layer_7'),\n",
       " ('permute', 'query_layer_8'),\n",
       " ('permute', 'query_layer_9'),\n",
       " ('permute', 'value_layer'),\n",
       " ('permute', 'value_layer_1'),\n",
       " ('permute', 'value_layer_10'),\n",
       " ('permute', 'value_layer_11'),\n",
       " ('permute', 'value_layer_2'),\n",
       " ('permute', 'value_layer_3'),\n",
       " ('permute', 'value_layer_4'),\n",
       " ('permute', 'value_layer_5'),\n",
       " ('permute', 'value_layer_6'),\n",
       " ('permute', 'value_layer_7'),\n",
       " ('permute', 'value_layer_8'),\n",
       " ('permute', 'value_layer_9'),\n",
       " ('transpose', 'embeddings'),\n",
       " ('view', 'context_layer_11'),\n",
       " ('view', 'context_layer_14'),\n",
       " ('view', 'context_layer_17'),\n",
       " ('view', 'context_layer_2'),\n",
       " ('view', 'context_layer_20'),\n",
       " ('view', 'context_layer_23'),\n",
       " ('view', 'context_layer_26'),\n",
       " ('view', 'context_layer_29'),\n",
       " ('view', 'context_layer_32'),\n",
       " ('view', 'context_layer_35'),\n",
       " ('view', 'context_layer_5'),\n",
       " ('view', 'context_layer_8'),\n",
       " ('view', 'x'),\n",
       " ('view', 'x_1'),\n",
       " ('view', 'x_10'),\n",
       " ('view', 'x_11'),\n",
       " ('view', 'x_12'),\n",
       " ('view', 'x_13'),\n",
       " ('view', 'x_14'),\n",
       " ('view', 'x_15'),\n",
       " ('view', 'x_16'),\n",
       " ('view', 'x_17'),\n",
       " ('view', 'x_18'),\n",
       " ('view', 'x_19'),\n",
       " ('view', 'x_2'),\n",
       " ('view', 'x_20'),\n",
       " ('view', 'x_21'),\n",
       " ('view', 'x_22'),\n",
       " ('view', 'x_23'),\n",
       " ('view', 'x_24'),\n",
       " ('view', 'x_25'),\n",
       " ('view', 'x_26'),\n",
       " ('view', 'x_27'),\n",
       " ('view', 'x_28'),\n",
       " ('view', 'x_29'),\n",
       " ('view', 'x_3'),\n",
       " ('view', 'x_30'),\n",
       " ('view', 'x_31'),\n",
       " ('view', 'x_32'),\n",
       " ('view', 'x_33'),\n",
       " ('view', 'x_34'),\n",
       " ('view', 'x_35'),\n",
       " ('view', 'x_4'),\n",
       " ('view', 'x_5'),\n",
       " ('view', 'x_6'),\n",
       " ('view', 'x_7'),\n",
       " ('view', 'x_8'),\n",
       " ('view', 'x_9'),\n",
       " (<function _operator.add(a, b, /)>, 'embeddings_2'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_10'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_15'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_18'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_2'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_23'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_26'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_31'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_34'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_39'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_42'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_47'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_50'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_55'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_58'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_63'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_66'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_7'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_71'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_74'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_79'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_82'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_87'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_90'),\n",
       " (<function _operator.add(a, b, /)>, 'hidden_states_95'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_12'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_20'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_28'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_36'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_4'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_44'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_52'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_60'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_68'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_76'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_84'),\n",
       " (<function torch._C._nn.gelu>, 'hidden_states_92'),\n",
       " (<function _operator.getitem(a, b, /)>, 'first_token_tensor'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_11'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_13'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_16'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_19'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_21'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_24'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_27'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_29'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_3'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_32'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_35'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_37'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_40'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_43'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_45'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_48'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_5'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_51'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_53'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_56'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_59'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_61'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_64'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_67'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_69'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_72'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_75'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_77'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_8'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_80'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_83'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_85'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_88'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_91'),\n",
       " (<function torch._C._nn.linear>, 'hidden_states_93'),\n",
       " (<function torch._C._nn.linear>, 'linear_1'),\n",
       " (<function torch._C._nn.linear>, 'linear_13'),\n",
       " (<function torch._C._nn.linear>, 'linear_14'),\n",
       " (<function torch._C._nn.linear>, 'linear_19'),\n",
       " (<function torch._C._nn.linear>, 'linear_2'),\n",
       " (<function torch._C._nn.linear>, 'linear_20'),\n",
       " (<function torch._C._nn.linear>, 'linear_25'),\n",
       " (<function torch._C._nn.linear>, 'linear_26'),\n",
       " (<function torch._C._nn.linear>, 'linear_31'),\n",
       " (<function torch._C._nn.linear>, 'linear_32'),\n",
       " (<function torch._C._nn.linear>, 'linear_37'),\n",
       " (<function torch._C._nn.linear>, 'linear_38'),\n",
       " (<function torch._C._nn.linear>, 'linear_43'),\n",
       " (<function torch._C._nn.linear>, 'linear_44'),\n",
       " (<function torch._C._nn.linear>, 'linear_49'),\n",
       " (<function torch._C._nn.linear>, 'linear_50'),\n",
       " (<function torch._C._nn.linear>, 'linear_55'),\n",
       " (<function torch._C._nn.linear>, 'linear_56'),\n",
       " (<function torch._C._nn.linear>, 'linear_61'),\n",
       " (<function torch._C._nn.linear>, 'linear_62'),\n",
       " (<function torch._C._nn.linear>, 'linear_67'),\n",
       " (<function torch._C._nn.linear>, 'linear_68'),\n",
       " (<function torch._C._nn.linear>, 'linear_7'),\n",
       " (<function torch._C._nn.linear>, 'linear_8'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_1'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_10'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_11'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_2'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_3'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_4'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_5'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_6'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_7'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_8'),\n",
       " (<function torch._C._nn.linear>, 'mixed_query_layer_9'),\n",
       " (<function torch._C._nn.linear>, 'pooled_output'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_12'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_15'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_18'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_21'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_24'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_27'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_3'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_30'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_33'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_6'),\n",
       " (<function torch._C._nn.scaled_dot_product_attention>, 'context_layer_9'),\n",
       " (<function torch._VariableFunctionsClass.cat>, 'embeddings_1'),\n",
       " (<function torch._VariableFunctionsClass.conv2d>, 'conv2d'),\n",
       " (<function torch._VariableFunctionsClass.tanh>, 'pooled_output_1'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'embeddings_3'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_1'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_14'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_17'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_22'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_25'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_30'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_33'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_38'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_41'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_46'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_49'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_54'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_57'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_6'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_62'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_65'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_70'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_73'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_78'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_81'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_86'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_89'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_9'),\n",
       " (<function torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor>,\n",
       "  'hidden_states_94'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_10'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_12'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_14'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_16'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_18'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_2'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_20'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_22'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_4'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_6'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_norm_8'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_1'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_10'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_11'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_2'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_3'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_4'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_5'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_6'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_7'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_8'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'layer_output_9'),\n",
       " (<function torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor>,\n",
       "  'sequence_output')}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set((n.target, n.name) for n in graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5246546-6c87-436c-ba3c-bb7c91f96ab5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "name2node_map = {\n",
    "    n.name: n\n",
    "    for n in graph.nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93282f0f-8927-418a-9a4f-e5f38a0291cb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "node = name2node_map[\"linear_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ab2bf68-6171-4986-ae59-8d934d91755e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "linear(input, weight, bias=None) -> Tensor\n",
       "\n",
       "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
       "\n",
       "This operation supports 2-D :attr:`weight` with :ref:`sparse layout<sparse-docs>`\n",
       "\n",
       "\n",
       ".. warning::\n",
       "    Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,\n",
       "    or may not have autograd support. If you notice missing functionality please\n",
       "    open a feature request.\n",
       "\n",
       "This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "Shape:\n",
       "\n",
       "    - Input: :math:`(*, in\\_features)` where `*` means any number of\n",
       "      additional dimensions, including none\n",
       "    - Weight: :math:`(out\\_features, in\\_features)` or :math:`(in\\_features)`\n",
       "    - Bias: :math:`(out\\_features)` or :math:`()`\n",
       "    - Output: :math:`(*, out\\_features)` or :math:`(*)`, based on the shape of the weight\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node.target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa26fbed-db2d-4400-94b2-95923d8a79e4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(layer_norm_2,\n",
       " l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_,\n",
       " l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_bias_)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fab3d9c0-a9ab-40dd-af48-1df13dd45413",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2node_map[\"x_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4021ca18-b3e9-4fc6-98a5-e197387aaf4f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "ph = name2node_map[\"l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f589c718-e3c8-4281-9c39-03ee73b4bd2e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph.meta[\"example_value\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6d754b0c-3582-4872-af5f-b0de7067c87a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.meta[\"example_value\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b920308-5629-49e8-8b19-057133520e60",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play-torch",
   "language": "python",
   "name": "play-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
